# TODOs
- When a test is killed by logger it includes the characters '\n' in the message
- document and create release for the test server, along with an [issue template](https://help.github.com/en/articles/about-issue-and-pull-request-templates)
- add more tests - unit and integration - get code coverage -- add in negative tests
  - split config parser into sub-crate and add in unit tests
  - add in integration test which drops connections before the body is fully sent
- Have a `secure` provider where values are blanked out in logs (only the original value is included in the request and trying to select it from a `provides` or `logs` should make the value appear as asterisks)
- allow load_patterns/config to change while a test is running. Monitor the load test config file for changes
- HARD - Allow declare expressions to reference other declare variables as long as there's no recursive references
- get rid of `static` providers and have a separate `static` section in the config. Also get rid of environment variable syntax and instead allow a static variable to be from an environment variable or a literal. *Breaking change*. Version 0.5.
- change the behavior of `send: block` to drop items if the current buffer is full but other `send: block` provides have room in their buffers. Can be implemented using `future::select_all` combined with a custom future impl that when dropped will do a `try_send` if it did not finish. *Breaking change*. Version 0.5
- change the default provides.send option to be `if_not_full` if the endpoint has a peak_load, otherwise `block`. *Breaking change*. Version 0.5.
- Merge `stats_id` and `alias`. New property `labels`, which would be key/value pairs just like `stats_id`. When specifying which endpoint to use for a try run key/value pairs can be specified to select 1 or more endpoints. *Breaking change*. Version 0.5.
- Break `run` and `try` into separate cli sub-commands. Add in different configuration options.
    - `try`: peakload, file output (defaults to stdout), format (could have simple, full, json--which would be intended for a viewer), allow-http-errors (change the default behavior to exit on any 4xx or 5xx errors), enable loggers (currently they are enabled but they should be disabled by default), parallel (the current default - can be implemented with a non-repeating static_list provider with a single value which is auto_returned). `try` should have the option to select one or more endpoints based upon the labels (or run everything)
    - `run`: output format (currently in config.general.summary_output_format-- remove that option; include option to disable stats), results file, option to have html output (includes the results viewer). *Breaking change*. Version 0.5.
- Merge `connection_errors`, `connectionErrors`, `connectionErrorCount` in summary output into `test_errors`. *Breaking change*. Version 0.5.
- Have a way to log recoverable errors. Request and Response may not be available, but can be beneficial for debugging. Don't log them to stderr by default. *Breaking change*. Version 0.5
- Make the inclusive/exlusiveness of `collect`, `range`, and `repeat` consistent. *Breaking change*. Version 0.5.
- Create a try run viewer. Version > 0.5.
- Have a `stats` sub-command to read, merge, and print aggregate stats summaries. Also the ability to convert a json to html. Version > 0.5.
- Have ability to include providers and endpoints (and any provider dependencies) from another config file. Version > 0.5.
- Results viewer: show total summaries for each endpoint directly under the heading (instead of next to each chart). Display test time at the top of the page. Version > 0.5.
- In the stats file record the name of the yaml file. Version > 0.5
- Adjust expression parsing errors to have line numbers which match with the yaml file
- Have a way to set an SLA for an endpoint and visualize that in the results. Also have a stats.SLA property that could be used to key logging off of.
- Handle ctrl-c and write out test summary and persist result to disk.
- Log when a request is waiting for a provider (use tokio trace)
- Add metrics for bytes sent/received per endpoint (total per bucket?)
- Have the Dockerfile and sh script cross compile for windows as well (see https://stackoverflow.com/a/39184296, https://github.com/est31/msvc-wine-rust)
- Create server mode:
  - Allows the running of tests on demand.
  - Live UI to see the progress of running tests.
  - No access to environment variables from configs.
  - Files for file providers will need to be included with the test as the server should not access any files on disk.
  - Loggers cannot write to files or stdout/stderr--everything should be displayed in the test results view.
  - Need ability to write stats to a log to be ingested by splunk.
  - Have a domain whitelist--only explicitly specified domains can be hit in a test.
  - Storage layer to store server config, tests and results
  - User permissions: roles to run a test, see results, create a test
- Add in machine clustering (only in server mode). Machines should open up a secure connection using a PSK
- track system health (sysinfo crate) perhaps event loop latency and determine if system is overloaded
- Add `with` support so we can have nested selects. `with` should be key value pairs where the value is an object with `with`*, `select`, `for_each`* and `where`* pieces
- Create a Visual Studio Code language extension for the loadtest file schema. Perhaps we only need a json schema (https://code.visualstudio.com/docs/languages/json#_json-schemas-settings)